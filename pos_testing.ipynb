{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextualData.TextualData\n",
    "import LSTM.lstm as lstm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = TextualData.TextualData.TextualData(path='data/full_shak_eng.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 200000 100000\n",
      "200000 300000 100000\n",
      "300000 400000 100000\n",
      "400000 500000 100000\n",
      "500000 600000 100000\n",
      "600000 700000 100000\n",
      "700000 800000 100000\n",
      "800000 900000 100000\n",
      "900000 1000000 100000\n",
      "1000000 1100000 100000\n",
      "1100000 1200000 100000\n",
      "1200000 1300000 100000\n",
      "1300000 1400000 100000\n",
      "1400000 1500000 100000\n",
      "1500000 1600000 100000\n",
      "1600000 1700000 100000\n",
      "1700000 1800000 100000\n",
      "1800000 1900000 100000\n",
      "1900000 2000000 100000\n",
      "2000000 2100000 100000\n",
      "2100000 2147990 100000\n",
      "2147990 2147990 47990\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text.full_text[:300000])\n",
    "allpos = set([tok.pos_ for tok in doc])\n",
    "pos_to_ix = {}\n",
    "ix_to_pos = {}\n",
    "ix=0\n",
    "for pos in allpos:\n",
    "    pos_to_ix[pos]=ix\n",
    "    ix_to_pos[ix]=pos\n",
    "    ix+=1\n",
    "mylen = 100000\n",
    "begin = 0\n",
    "end = mylen\n",
    "full_pos = []\n",
    "while begin < len(text.full_text):\n",
    "    mystr = text.full_text[begin:end]\n",
    "    begin = end\n",
    "    end = min(end+mylen, len(text.full_text))\n",
    "    doc = nlp(mystr)\n",
    "    pos_by_char = []\n",
    "    for tok in doc:\n",
    "        pos_by_char.append([pos_to_ix[tok.pos_] for l in tok.text_with_ws])\n",
    "    pos_by_char = np.array([item for sublist in pos_by_char for item in sublist])\n",
    "    full_pos.append(pos_by_char)\n",
    "    print begin, end, len(pos_by_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pos = [item for sublist in full_pos for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147990\n",
      "2147991\n"
     ]
    }
   ],
   "source": [
    "print len(full_pos)\n",
    "print len(text.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "string_len = 10\n",
    "batch_size = 1\n",
    "stride = 1\n",
    "\n",
    "if start + string_len * batch_size >= text.train_len:\n",
    "    raise IndexError('Not enough text to return this batch')\n",
    "batch = []\n",
    "st = start\n",
    "for i in range(batch_size):\n",
    "    batch.append(text.string_to_tensor(text.train_text[st:st + string_len]))\n",
    "    st += string_len - 1\n",
    "# batch = [self.string_to_tensor(self.random_string_fixed_size(string_len)) for i in range(batch_size)]\n",
    "targets = [torch.cat([text.onehot_to_class(b[0]) for b in batch[bn][stride:]]) for bn in range(batch_size)]\n",
    "batch = torch.cat(batch, dim=1)[:string_len - stride]\n",
    "batch = [[batch[:, i], targets[i]] for i in range(batch_size)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
