{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextualData.TextualData\n",
    "import LSTM.lstm as lstm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import spacy\n",
    "import time\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "batch_size = 2\n",
    "string_len = 2\n",
    "valid_batches = 2\n",
    "n_layers = 2\n",
    "starting_lr = .025\n",
    "lr_decay_factor = 2.\n",
    "pos = 1\n",
    "#Train the network to predict the charachter appearing after stride - Leave = 1\n",
    "stride = 1\n",
    "gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(TextualData.TextualData)\n",
    "text = TextualData.TextualData.TextualData(path='data/full_shak_eng.txt', \n",
    "                                           lower=True, lines=100000, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing POS...\n",
      "Created POS data. Train_pos len: 60000 Valid_pos len: 20000\n",
      "POS computed\n",
      "alpha len 39 pos len 16 product 624\n"
     ]
    }
   ],
   "source": [
    "print 'Computing POS...'\n",
    "text.compute_pos()\n",
    "print 'POS computed'\n",
    "print 'alpha len', text.alpha_len, 'pos len', text.pos_len, 'product', text.alpha_len*text.pos_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = text.get_batch(100,50,0,pos=True)\n",
    "inputs = torch.stack([b[0] for b in bc])\n",
    "labels = torch.stack([b[1] for b in bc])\n",
    "if gpu is True:\n",
    "    inputs=inputs.cuda()\n",
    "    labels=labels.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pos == 1:\n",
    "    rnn = lstm.LSTMmodel(hidden_s=hidden_size, \n",
    "                         input_s=text.alpha_len*text.pos_len, n_layers=n_layers, gpu=gpu)\n",
    "else:\n",
    "    rnn = lstm.LSTMmodel(hidden_s=hidden_size, \n",
    "                         input_s=text.alpha_len, n_layers=n_layers, gpu=gpu)\n",
    "if gpu is True:\n",
    "    rnn=rnn.cuda()\n",
    "rnn.optimizer = optim.Adam(rnn.parameters(), lr=starting_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865807056427002"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=time.time()\n",
    "np.mean([rnn.loss_func(rnn.forward(inputs[i]), labels[i]) for i in range(50)])\n",
    "time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18831110001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6002740859985352"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=time.time()\n",
    "fw=rnn.forward(inputs)\n",
    "print time.time()-t\n",
    "t=time.time()\n",
    "fw=[rnn.forward(i) for i in inputs]\n",
    "time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 624])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00796794891357\n",
      "starting valid loss 5.76587677002\n"
     ]
    }
   ],
   "source": [
    "print_every = 5\n",
    "update_every = 50\n",
    "tot_loss=0\n",
    "t = time.time()\n",
    "valid_loss = np.mean([rnn.loss_func(rnn.forward(inp), tar) for inp, tar in\n",
    "                      text.get_valid_batch(string_len,valid_batches,0,stride,pos)]).data[0]\n",
    "print time.time()-t\n",
    "print 'starting valid loss', valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'/tmp/tmpNqXk2H'. \n"
     ]
    }
   ],
   "source": [
    "%snakeviz 1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'/tmp/tmpCJdLfs'. \n"
     ]
    }
   ],
   "source": [
    "inp, tar = text.get_valid_batch(string_len,valid_batches,0,stride,pos)\n",
    "%snakeviz rnn.forward(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(10):\n",
    "    my_loss = rnn.train(text.get_batch(string_len,batch_size,index,stride,pos))\n",
    "    print my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvar = Variable(torch.cuda.LongTensor(np.zeros(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.variable.Variable"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testvar.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.LongTensor of size 10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print testvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMmodel(\n",
       "  (lstm): LSTM(256, 256, num_layers=2, dropout=0.25)\n",
       "  (linear): Linear(in_features=256, out_features=848)\n",
       "  (embedding): Linear(in_features=848, out_features=256)\n",
       "  (logsoft): LogSoftmax()\n",
       "  (loss_func): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp1=np.random.rand(150,45000)\n",
    "mcp2=np.random.rand(45000,150)\n",
    "mcp1gpu=torch.Tensor(mcp1).cuda()\n",
    "mcp2gpu=torch.Tensor(mcp2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2622449398\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "r1=[np.matmul(mcp1,mcp2) for i in range(100)]\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00578308105469\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "r2=[torch.matmul(mcp1gpu,mcp2gpu) for i in range(100)]\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11252.26541279, 11232.52284088, 11268.73060936, 11212.88691092,\n",
       "       11264.94852029, 11245.24881578, 11291.23688647, 11204.89055259,\n",
       "       11264.43886082, 11266.4704157 , 11264.8395667 , 11242.15466876,\n",
       "       11275.41307562, 11283.38891701, 11227.61443004, 11252.20640174,\n",
       "       11264.40516247, 11236.30388645, 11303.3395822 , 11235.141521  ,\n",
       "       11246.36786597, 11236.13263528, 11162.67438639, 11221.64476667,\n",
       "       11238.901956  , 11225.71865702, 11256.19390092, 11276.12626838,\n",
       "       11294.25633129, 11259.66807267, 11256.3319513 , 11257.22308769,\n",
       "       11261.12631686, 11258.53771383, 11285.778175  , 11227.73521397,\n",
       "       11245.76426599, 11237.94470397, 11184.68507752, 11242.50919729,\n",
       "       11230.03637027, 11335.32607909, 11302.09605179, 11261.48829391,\n",
       "       11296.52778688, 11281.40835076, 11261.96775412, 11259.23744156,\n",
       "       11231.03431951, 11294.75169432, 11214.27553918, 11291.45597562,\n",
       "       11311.24953019, 11231.34006565, 11269.36284305, 11219.84541271,\n",
       "       11253.80799159, 11281.44538333, 11287.09820226, 11338.51674878,\n",
       "       11228.2117177 , 11192.09635977, 11236.60095722, 11309.67330259,\n",
       "       11256.46196875, 11221.7291749 , 11273.43008747, 11307.1964375 ,\n",
       "       11288.32876971, 11221.80743244, 11250.38336583, 11283.63517984,\n",
       "       11210.89241896, 11273.42439447, 11272.16667495, 11275.75435542,\n",
       "       11252.31855324, 11288.94825242, 11297.93152798, 11156.7158871 ,\n",
       "       11323.20097791, 11226.17176483, 11248.58068172, 11263.07188198,\n",
       "       11231.17098888, 11306.60237601, 11232.41049206, 11307.33878507,\n",
       "       11307.07257964, 11265.37552642, 11298.27871365, 11265.88173065,\n",
       "       11304.79647471, 11280.32454873, 11247.80273864, 11269.43987702,\n",
       "       11302.17162705, 11188.66031709, 11234.6001011 , 11191.79826522,\n",
       "       11251.43578048, 11225.61257956, 11296.27658374, 11295.72451741,\n",
       "       11212.58348991, 11216.28992713, 11225.34855542, 11272.71194337,\n",
       "       11273.12677604, 11254.53253874, 11271.0635717 , 11260.23393003,\n",
       "       11221.73851315, 11237.09759095, 11265.4482831 , 11197.67237531,\n",
       "       11213.74581763, 11345.76135994, 11262.17046833, 11314.50238134,\n",
       "       11299.41504889, 11230.78094013, 11283.86703126, 11263.73377386,\n",
       "       11292.20648637, 11262.06992407, 11254.93658152, 11251.58508409,\n",
       "       11252.4313149 , 11244.15538462, 11253.02432446, 11255.54050379,\n",
       "       11216.06566649, 11181.46820516, 11325.64302204, 11311.22056117,\n",
       "       11282.98693455, 11273.65601246, 11269.11545175, 11243.35488651,\n",
       "       11257.46015835, 11251.31276859, 11189.87962886, 11285.88768459,\n",
       "       11291.29143556, 11301.91005163, 11242.21475491, 11277.51181859,\n",
       "       11292.7990801 , 11279.69567702])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 11252.2676\n",
       " 11232.5254\n",
       " 11268.7305\n",
       " 11212.8867\n",
       " 11264.9355\n",
       " 11245.2500\n",
       " 11291.2324\n",
       " 11204.8828\n",
       " 11264.4316\n",
       " 11266.4727\n",
       " 11264.8398\n",
       " 11242.1602\n",
       " 11275.4082\n",
       " 11283.3887\n",
       " 11227.6094\n",
       " 11252.2100\n",
       " 11264.4043\n",
       " 11236.3027\n",
       " 11303.3408\n",
       " 11235.1426\n",
       " 11246.3652\n",
       " 11236.1299\n",
       " 11162.6758\n",
       " 11221.6523\n",
       " 11238.8945\n",
       " 11225.7227\n",
       " 11256.1855\n",
       " 11276.1328\n",
       " 11294.2656\n",
       " 11259.6670\n",
       " 11256.3223\n",
       " 11257.2227\n",
       " 11261.1270\n",
       " 11258.5410\n",
       " 11285.7695\n",
       " 11227.7275\n",
       " 11245.7637\n",
       " 11237.9502\n",
       " 11184.6934\n",
       " 11242.5127\n",
       " 11230.0352\n",
       " 11335.3223\n",
       " 11302.0947\n",
       " 11261.4834\n",
       " 11296.5312\n",
       " 11281.4023\n",
       " 11261.9727\n",
       " 11259.2344\n",
       " 11231.0273\n",
       " 11294.7451\n",
       " 11214.2734\n",
       " 11291.4541\n",
       " 11311.2676\n",
       " 11231.3379\n",
       " 11269.3535\n",
       " 11219.8477\n",
       " 11253.8018\n",
       " 11281.4453\n",
       " 11287.1025\n",
       " 11338.5156\n",
       " 11228.2148\n",
       " 11192.0957\n",
       " 11236.6006\n",
       " 11309.6719\n",
       " 11256.4619\n",
       " 11221.7227\n",
       " 11273.4316\n",
       " 11307.1943\n",
       " 11288.3203\n",
       " 11221.8047\n",
       " 11250.3867\n",
       " 11283.6348\n",
       " 11210.8906\n",
       " 11273.4258\n",
       " 11272.1621\n",
       " 11275.7617\n",
       " 11252.3184\n",
       " 11288.9531\n",
       " 11297.9355\n",
       " 11156.7168\n",
       " 11323.1963\n",
       " 11226.1768\n",
       " 11248.5840\n",
       " 11263.0742\n",
       " 11231.1738\n",
       " 11306.5996\n",
       " 11232.4102\n",
       " 11307.3350\n",
       " 11307.0801\n",
       " 11265.3779\n",
       " 11298.2852\n",
       " 11265.8799\n",
       " 11304.7939\n",
       " 11280.3242\n",
       " 11247.8047\n",
       " 11269.4492\n",
       " 11302.1758\n",
       " 11188.6572\n",
       " 11234.5957\n",
       " 11191.7949\n",
       " 11251.4316\n",
       " 11225.6133\n",
       " 11296.2744\n",
       " 11295.7227\n",
       " 11212.5801\n",
       " 11216.2871\n",
       " 11225.3506\n",
       " 11272.7178\n",
       " 11273.1250\n",
       " 11254.5410\n",
       " 11271.0547\n",
       " 11260.2383\n",
       " 11221.7422\n",
       " 11237.0957\n",
       " 11265.4551\n",
       " 11197.6748\n",
       " 11213.7500\n",
       " 11345.7637\n",
       " 11262.1719\n",
       " 11314.4902\n",
       " 11299.4121\n",
       " 11230.7793\n",
       " 11283.8613\n",
       " 11263.7305\n",
       " 11292.2070\n",
       " 11262.0664\n",
       " 11254.9336\n",
       " 11251.5879\n",
       " 11252.4346\n",
       " 11244.1641\n",
       " 11253.0293\n",
       " 11255.5420\n",
       " 11216.0732\n",
       " 11181.4629\n",
       " 11325.6445\n",
       " 11311.2246\n",
       " 11282.9824\n",
       " 11273.6572\n",
       " 11269.1152\n",
       " 11243.3496\n",
       " 11257.4570\n",
       " 11251.3037\n",
       " 11189.8770\n",
       " 11285.8887\n",
       " 11291.2871\n",
       " 11301.9102\n",
       " 11242.2119\n",
       " 11277.5068\n",
       " 11292.7939\n",
       " 11279.6914\n",
       "[torch.cuda.FloatTensor of size 150 (GPU 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
